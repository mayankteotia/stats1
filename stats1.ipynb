{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4925b9f5-5e16-4c88-9bc5-27d654990bf4",
   "metadata": {},
   "source": [
    "q1-> \n",
    "### Types of Data: Qualitative and Quantitative\n",
    "\n",
    "Data can be categorized into **qualitative** (descriptive) and **quantitative** (numerical).\n",
    "\n",
    "---\n",
    "\n",
    " 1. Qualitative Data (Categorical Data) \n",
    "- Describes characteristics or qualities.\n",
    "- Not numerical and often categorized or labeled.\n",
    "\n",
    "- **Colors** of cars (red, blue, black).\n",
    "- **Types** of cuisine (Italian, Chinese, Indian).\n",
    "- **Gender** (male, female, non-binary).\n",
    "\n",
    "- **Nominal Data: \n",
    "  - Categories with no inherent order.\n",
    "  - Examples: Blood types (A, B, AB, O), phone brands (Samsung, Apple, Nokia).\n",
    "  \n",
    "- **Ordinal Data: \n",
    "  - Categories with a meaningful order but without consistent intervals.\n",
    "  - Examples: Customer satisfaction ratings (satisfied, neutral, dissatisfied), education levels (high school, bachelor's, master's).\n",
    "\n",
    "---\n",
    "\n",
    "  \n",
    "- Expresses quantities or amounts.\n",
    "- Can be measured or counted.\n",
    "\n",
    "- **Height* of students (in centimeters).\n",
    "- **Number of books* in a library.\n",
    "- **Temperature* in Celsius.\n",
    "- \n",
    "- **Interval Data*: \n",
    "  - Numerical data with equal intervals between values, but no true zero point.\n",
    "  - Examples: Temperature in Celsius or Fahrenheit (0°C does not mean no temperature), calendar years (2020, 2021).\n",
    "  \n",
    "\n",
    "  - Numerical data with equal intervals and a true zero point.\n",
    "  - Examples: Weight (0 kg indicates no weight), distance (0 km means no distance), salary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d229b4-2c88-415a-b1ce-a47dbb2ced97",
   "metadata": {},
   "source": [
    "Q2->\n",
    "### Measures of Central Tendency\n",
    "Measures of central tendency describe the center of a data set, summarizing it with a single value that represents a typical or central point. The three main measures are **mean**, **median**, and **mode**. Each is useful in different contexts.\n",
    "\n",
    "---\n",
    "\n",
    "*1. Mean (Average)**  \n",
    "- *Definition**: The sum of all data points divided by the total number of points.  \n",
    "  \\[\n",
    "  \\text{Mean} = \\frac{\\text{Sum of all values}}{\\text{Number of values}}\n",
    "  \\]\n",
    "  \n",
    "*Example**:  \n",
    "For the data set \\( [4, 8, 15, 16, 23, 42] \\):  \n",
    "\\[\n",
    "\\text{Mean} = \\frac{4 + 8 + 15 + 16 + 23 + 42}{6} = 18\n",
    "\\]\n",
    "\n",
    "When to Use**:  \n",
    "- Data is **symmetrical** (not skewed).\n",
    "- There are **no extreme outliers**, as they can distort the mean.\n",
    "\n",
    "*Example Situations**:  \n",
    "- Calculating the **average score** of students in a class.\n",
    "- Finding the **mean salary** in a company when salaries are relatively uniform.\n",
    "\n",
    "---\n",
    "\n",
    "*2. Median**  \n",
    "- **Definition**: The middle value when data is arranged in order. If there is an even number of data points, the median is the average of the two middle values.\n",
    "\n",
    "*Example**:  \n",
    "For the data set \\( [3, 7, 8, 12, 14] \\):  \n",
    "\\[\n",
    "\\text{Median} = 8\n",
    "\\]  \n",
    "For \\( [3, 7, 8, 12, 14, 20] \\):  \n",
    "\\[\n",
    "\\text{Median} = \\frac{8 + 12}{2} = 10\n",
    "\\]\n",
    "\n",
    "*When to Use**:  \n",
    "- Data is **skewed** or has **outliers**, as the median is unaffected by extreme values.\n",
    "\n",
    "*Example Situations**:  \n",
    "- Determining the **middle household income** in a region with a wide range of incomes.\n",
    "- Finding the **median house price** in a city with a mix of affordable and luxury homes.\n",
    "\n",
    "---\n",
    "\n",
    "3. Mode**  \n",
    "- **Definition**: The value(s) that occur most frequently in the data set. A data set can be unimodal (one mode), bimodal (two modes), or multimodal (multiple modes).\n",
    "\n",
    "Example**:  \n",
    "For the data set \\( [2, 3, 3, 7, 8, 8, 8] \\):  \n",
    "\\[\n",
    "\\text{Mode} = 8\n",
    "\\]  \n",
    "For \\( [1, 2, 3, 3, 4, 4] \\):  \n",
    "\\[\n",
    "\\text{Modes} = 3 \\text{ and } 4 \\, (\\text{bimodal})\n",
    "\\]\n",
    "\n",
    "When to Use**:  \n",
    "- Data is **categorical** or when you want the most common value.\n",
    "- Useful when mean and median are less informative (e.g., for nominal data).\n",
    "\n",
    "Example Situations**:  \n",
    "- Identifying the **most popular product** sold in a store.\n",
    "- Determining the **most common shoe size** among customers.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec543f3-cffd-4e99-80ea-7f3a5ea0c35c",
   "metadata": {},
   "source": [
    "Q3->\n",
    "#*Concept of Dispersion**\n",
    "\n",
    "Dispersion refers to the spread or variability of data in a dataset. It indicates how much the data points deviate from the central tendency (mean, median, or mode) and from each other. Measures of dispersion help understand the consistency, reliability, and range of the data.\n",
    "\n",
    "---\n",
    "\n",
    "*Key Measures of Dispersion**\n",
    "1. **Range**: The difference between the maximum and minimum values.\n",
    "   \\[\n",
    "   \\text{Range} = \\text{Max value} - \\text{Min value}\n",
    "   \\]\n",
    "\n",
    "2. **Variance**: The average of the squared differences from the mean.\n",
    "3. **Standard Deviation**: The square root of variance, providing a measure of spread in the same units as the data.\n",
    "\n",
    "---\n",
    "\n",
    "*Variance**\n",
    "Variance quantifies the average squared deviation of each data point from the mean. It is a measure of how data points vary around the mean.  \n",
    "\n",
    "*Formula**:\n",
    "For a population:\n",
    "\\[\n",
    "\\sigma^2 = \\frac{\\sum_{i=1}^N (x_i - \\mu)^2}{N}\n",
    "\\]\n",
    "For a sample:\n",
    "\\[\n",
    "s^2 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n - 1}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( x_i \\): Individual data point\n",
    "- \\( \\mu \\): Population mean\n",
    "- \\( \\bar{x} \\): Sample mean\n",
    "- \\( N \\): Population size\n",
    "- \\( n \\): Sample size\n",
    "\n",
    " *Key Points**:\n",
    "- Units of variance are the square of the original data's units (e.g., if data is in meters, variance is in square meters).\n",
    "- Large variance indicates greater spread in the data.\n",
    "\n",
    "*Example**:\n",
    "For the data \\( [2, 4, 6, 8] \\) (mean = 5):\n",
    "\\[\n",
    "\\text{Variance} = \\frac{(2-5)^2 + (4-5)^2 + (6-5)^2 + (8-5)^2}{4} = \\frac{9 + 1 + 1 + 9}{4} = 5\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "*Standard Deviation**\n",
    "The standard deviation is the square root of the variance. It expresses the spread of data in the same units as the original data, making it more interpretable than variance.\n",
    "\n",
    "*Formula**:\n",
    "\\[\n",
    "\\sigma = \\sqrt{\\sigma^2} \\quad \\text{(for population)}, \\quad s = \\sqrt{s^2} \\quad \\text{(for sample)}\n",
    "\\]\n",
    "\n",
    "*Key Points**:\n",
    "- A small standard deviation indicates that data points are close to the mean.\n",
    "- A large standard deviation suggests greater variability.\n",
    "\n",
    "Example**:\n",
    "Using the previous variance example (\\( \\sigma^2 = 5 \\)):\n",
    "\\[\n",
    "\\text{Standard Deviation} = \\sqrt{5} \\approx 2.24\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "*Variance vs. Standard Deviation**\n",
    "| **Measure*          | **Variance*                     | *Standard Deviation**            |\n",
    "|-----------------------|----------------------------------|------------------------------------|\n",
    "| **Definition*        | Average squared deviation       | Square root of variance           |\n",
    "| **Units*          | Square of original units        | Same as original data             |\n",
    "|*Interpretability**  | Less interpretable              | More intuitive and practical      |\n",
    "\n",
    "---\n",
    "\n",
    "*Why Use Variance and Standard Deviation?**\n",
    "\n",
    "- *Variance** is essential for theoretical and statistical computations, such as in hypothesis testing and machine learning models.\n",
    "- *Standard Deviation** is preferred for interpretation in real-world applications because it matches the original data's scale.\n",
    "\n",
    "---\n",
    "\n",
    " **Summary*\n",
    "Variance and standard deviation measure dispersion by quantifying how far data points are from the mean:\n",
    "- Variance captures the average squared deviations.\n",
    "- Standard deviation transforms variance into a more interpretable form, aligning with the original units of the data. Together, they provide a deeper understanding of the variability in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549390f4-cdba-406b-ae1c-caaf195c46d2",
   "metadata": {},
   "source": [
    "Q4->\n",
    "### **What is a Box Plot?*\n",
    "\n",
    "A **box plot* (or *box-and-whisker plot**) is a graphical representation of a dataset that summarizes its central tendency, spread, and potential outliers. It provides a visual snapshot of the distribution of data based on five key summary statistics:\n",
    "\n",
    "1. **Minimum*: The smallest data point (excluding outliers).\n",
    "2. *First Quartile (Q1)**: The value below which 25% of the data falls.\n",
    "3. *Median (Q2)**: The middle value of the dataset (50th percentile).\n",
    "4. *Third Quartile (Q3)**: The value below which 75% of the data falls.\n",
    "5. *Maximum**: The largest data point (excluding outliers).\n",
    "\n",
    "Additionally, **outliers** are often marked as individual points outside the \"whiskers.\"\n",
    "\n",
    "---\n",
    "\n",
    "##*Components of a Box Plot**\n",
    "\n",
    "1. *Box**:\n",
    "   - The rectangle spans from **Q1** to **Q3**.\n",
    "   - Represents the **interquartile range (IQR)**: \\( \\text{IQR} = Q3 - Q1 \\).\n",
    "   - Contains the middle 50% of the data.\n",
    "\n",
    "2. *Median Line**:\n",
    "   - A line inside the box indicates the **median**.\n",
    "\n",
    "3. *Whiskers**:\n",
    "   - Lines extending from the box to the smallest and largest data points within \\( 1.5 \\times \\text{IQR} \\) from the quartiles.\n",
    "   - Whiskers do not include outliers.\n",
    "\n",
    "4. *Outliers**:\n",
    "   - Points beyond \\( 1.5 \\times \\text{IQR} \\) from Q1 or Q3.\n",
    "   - Typically plotted as dots or asterisks.\n",
    "\n",
    "---\n",
    "\n",
    "#*What a Box Plot Reveals**\n",
    "\n",
    "1. *Central Tendency**:\n",
    "   - The **median** provides a visual representation of the center of the dataset.\n",
    "\n",
    "2. *Spread of Data**:\n",
    "   - The **IQR** shows the variability of the middle 50% of the data.\n",
    "   - The total range (distance from minimum to maximum) gives insight into overall variability.\n",
    "\n",
    "3. *Skewness**:\n",
    "   - If the box is shifted or one whisker is significantly longer, the data is skewed.\n",
    "   - Example:\n",
    "     - Longer whisker on the right: **right-skewed**.\n",
    "     - Longer whisker on the left: **left-skewed**.\n",
    "\n",
    "4. *Outliers**:\n",
    "   - Highlights unusual data points that deviate significantly from the rest of the dataset.\n",
    "\n",
    "5. *Symmetry**:\n",
    "   - If the median is centered within the box and the whiskers are roughly equal in length, the distribution is approximately symmetrical.\n",
    "\n",
    "---\n",
    "\n",
    "##*Example**\n",
    "For a dataset: \\( [2, 4, 5, 7, 8, 10, 12, 14, 16, 18] \\):\n",
    "- Minimum: \\( 2 \\)\n",
    "- Q1: \\( 6 \\)\n",
    "- Median: \\( 10 \\)\n",
    "- Q3: \\( 14 \\)\n",
    "- Maximum: \\( 18 \\)\n",
    "\n",
    "The box plot for this data would show:\n",
    "- A box from \\( 6 \\) to \\( 14 \\) with a median line at \\( 10 \\).\n",
    "- Whiskers extending to \\( 2 \\) and \\( 18 \\).\n",
    "- No outliers, as no points fall beyond \\( 1.5 \\times \\text{IQR} \\).\n",
    "\n",
    "---\n",
    "\n",
    " *Advantages of a Box Plot**\n",
    "- Summarizes large datasets with minimal visual clutter.\n",
    "- Highlights outliers and skewness effectively.\n",
    "- Enables quick comparison between multiple datasets.\n",
    "\n",
    "#Limitations**\n",
    "- Does not display the actual frequency distribution.\n",
    "- Cannot indicate modes or precise shape of the distribution (e.g., bimodality).\n",
    "\n",
    "Box plots are a powerful tool for exploratory data analysis, offering a concise and clear way to understand the key aspects of data distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604a2ed9-4398-4d67-89be-7f05bfca7334",
   "metadata": {},
   "source": [
    "Q5->\n",
    "The Role of Random Sampling in Making Inferences About Populations**\n",
    "\n",
    "**Random sampling** is a fundamental method in statistics that involves selecting a subset of individuals, items, or observations from a larger population in such a way that every member of the population has an equal chance of being included in the sample. This method is essential for drawing reliable and unbiased inferences about the population.\n",
    "\n",
    "---\n",
    "\n",
    "Key Principles of Random Sampling**\n",
    "\n",
    "1. *Representativeness**:  \n",
    "   Random sampling aims to ensure that the sample represents the characteristics of the population. A representative sample allows generalizations to the entire population with minimal bias.\n",
    "\n",
    "2. *Elimination of Bias**:  \n",
    "   Since each member of the population has an equal probability of selection, random sampling reduces systematic bias in the selection process.\n",
    "\n",
    "3. *Basis for Inference**:  \n",
    "   Random samples form the foundation for statistical inference, enabling researchers to make predictions, test hypotheses, and estimate population parameters.\n",
    "\n",
    "---\n",
    "\n",
    "*Role in Making Inferences**\n",
    "\n",
    "1. *Generalization of Results**:\n",
    "   Random sampling allows conclusions drawn from the sample to be extended to the entire population. For example, if you survey 500 randomly selected voters, you can infer voting preferences for the entire electorate with a degree of confidence.\n",
    "\n",
    "2. *Estimation of Population Parameters**:\n",
    "   - Using random sampling, statistics like the sample mean (\\( \\bar{x} \\)) or sample proportion (\\( \\hat{p} \\)) can estimate population parameters such as the population mean (\\( \\mu \\)) or proportion (\\( p \\)).\n",
    "   - These estimates include a margin of error, reflecting sampling variability.\n",
    "\n",
    "3. *Hypothesis Testing**:\n",
    "   - Random samples provide a basis for testing hypotheses about population characteristics. For example, you can test whether the average income of a population exceeds a certain threshold.\n",
    "\n",
    "4. \\*Reliability and Validity**:\n",
    "   - Random sampling supports the validity of statistical methods by ensuring the assumptions (e.g., independence of observations, normality in large samples) are met.\n",
    "   - Results based on random samples can be trusted to have higher reliability than those from non-random samples.\n",
    "\n",
    "---\n",
    "\n",
    "#Example**\n",
    "Suppose a company wants to determine the average monthly expenditure of its customers. Instead of surveying all 10,000 customers, it selects a random sample of 500 customers. If the average expenditure in the sample is $200 with a standard error of $5, the company can infer with confidence intervals that the population mean lies close to $200.\n",
    "\n",
    "---\n",
    "\n",
    "#*Advantages of Random Sampling\n",
    "\n",
    "1. *Unbiased Selection**:\n",
    "   Every individual has an equal chance of being included, reducing selection bias.\n",
    "   \n",
    "2. *Simplifies Analysis**:\n",
    "   Statistical formulas and techniques assume random sampling, making analyses straightforward and valid.\n",
    "\n",
    "3. *Cost-Effectiveness**:\n",
    "   Studying a random sample is more efficient and less expensive than surveying the entire population.\n",
    "\n",
    "4. *Supports Laws of Probability**:\n",
    "   Random samples align with probability theory, allowing for accurate predictions about population parameters.\n",
    "\n",
    "---\n",
    "\n",
    "#*Challenges and Limitations**\n",
    "\n",
    "1. *Sampling Error**:\n",
    "   - Random samples are subject to sampling error, where the sample statistic deviates from the true population parameter.\n",
    "   - Larger samples reduce sampling error.\n",
    "\n",
    "2. *Practical Implementation**:\n",
    "   - Ensuring truly random sampling can be logistically challenging and expensive in some situations.\n",
    "   \n",
    "3. *Non-Response Bias**:\n",
    "   - If selected participants do not respond, the sample may no longer represent the population accurately.\n",
    "\n",
    "---\n",
    "\n",
    "*Conclusion**\n",
    "\n",
    "Random sampling is critical for making reliable inferences about populations because it ensures representativeness and minimizes bias. By providing a solid foundation for statistical analysis, it allows researchers to estimate population parameters, test hypotheses, and generalize findings effectively. However, careful implementation and consideration of potential biases are necessary to maintain its validity."
   ]
  },
  {
   "cell_type": "raw",
   "id": "94adb20e-a9fb-4c92-9ca7-011fb3600594",
   "metadata": {},
   "source": [
    "Q6->\n",
    "### **Concept of Skewness**\n",
    "\n",
    "**Skewness** is a measure of the asymmetry in the distribution of data. A dataset is symmetric if it looks identical on both sides of its central value. Skewness indicates whether the data tails off more to the right or the left and helps identify deviations from normality.\n",
    "\n",
    "---\n",
    "\n",
    "### **Types of Skewness**\n",
    "\n",
    "1. **Symmetrical Distribution**:\n",
    "   - The data is evenly distributed around the mean.\n",
    "   - Mean = Median = Mode.\n",
    "   - Example: The heights of adults in a population often follow a symmetrical distribution.\n",
    "\n",
    "   **Graph Shape**: Bell-shaped (like a normal distribution).\n",
    "\n",
    "2. **Positive Skew (Right-Skewed)**:\n",
    "   - The tail is longer on the right side of the distribution.\n",
    "   - Most data points are concentrated on the lower end.\n",
    "   - Mean > Median > Mode.\n",
    "   - Example: Income distribution in many societies, where a few individuals have extremely high incomes.\n",
    "\n",
    "   **Graph Shape**: Tail stretches to the right.\n",
    "\n",
    "3. **Negative Skew (Left-Skewed)**:\n",
    "   - The tail is longer on the left side of the distribution.\n",
    "   - Most data points are concentrated on the higher end.\n",
    "   - Mean < Median < Mode.\n",
    "   - Example: Age at retirement, where most individuals retire at a standard age, but a few retire much earlier.\n",
    "\n",
    "   **Graph Shape**: Tail stretches to the left.\n",
    "\n",
    "---\n",
    "\n",
    "### **Quantifying Skewness**\n",
    "\n",
    "Skewness is often measured using a statistical formula. For a dataset of size \\( n \\), the skewness coefficient is:\n",
    "\\[\n",
    "\\text{Skewness} = \\frac{\\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^3}{\\left(\\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2\\right)^{\\frac{3}{2}}}\n",
    "\\]\n",
    "\n",
    "- **Skewness = 0**: Perfectly symmetric distribution.\n",
    "- **Skewness > 0**: Positively skewed (tail on the right).\n",
    "- **Skewness < 0**: Negatively skewed (tail on the left).\n",
    "\n",
    "---\n",
    "\n",
    "### **How Skewness Affects Data Interpretation**\n",
    "\n",
    "1. **Impact on Central Tendency**:\n",
    "   - In skewed data, the **mean** is pulled toward the tail, making it less reliable as a measure of central tendency.\n",
    "   - The **median** is often preferred because it is not affected by extreme values.\n",
    "   \n",
    "   **Example**: For a positively skewed income dataset:\n",
    "   - Mean income may appear higher due to a few very high incomes.\n",
    "   - Median income provides a better representation of the \"typical\" income.\n",
    "\n",
    "2. **Choosing Statistical Tests**:\n",
    "   - Many parametric tests assume normality (symmetry). For highly skewed data, non-parametric tests (e.g., Mann-Whitney U test) may be more appropriate.\n",
    "\n",
    "3. **Data Transformation**:\n",
    "   - Skewed data often benefits from transformation (e.g., log, square root) to reduce skewness and make the data more normal-like for analysis.\n",
    "\n",
    "4. **Outliers and Decision-Making**:\n",
    "   - Skewness can indicate the presence of **outliers** in the tails, which may need to be addressed before analysis.\n",
    "   - **Example**: In stock price returns, positive skewness may signal the potential for large, infrequent gains.\n",
    "\n",
    "5. **Predictive Modeling**:\n",
    "   - In machine learning and regression, skewed data can lead to biased models if not handled appropriately.\n",
    "   - Transforming or normalizing skewed data ensures better model performance.\n",
    "\n",
    "---\n",
    "\n",
    "### **Visualizing Skewness**\n",
    "\n",
    "Skewness is often visualized using:\n",
    "- **Histograms**: Show the shape of the data.\n",
    "- **Box Plots**: Highlight skewness through the position of the median and length of whiskers.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Skewness provides valuable insights into the asymmetry of data distributions. Recognizing whether data is positively or negatively skewed helps in choosing the correct measures of central tendency, statistical tests, and transformations. Properly addressing skewness ensures more accurate and reliable interpretations of data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "890c9183-7fac-4c9e-8dde-fd9a7b19a356",
   "metadata": {},
   "source": [
    "Q7->\n",
    "### **What is the Interquartile Range (IQR)?**\n",
    "\n",
    "The **Interquartile Range (IQR)** is a measure of statistical dispersion that represents the range within which the central 50% of the data lies. It is the difference between the third quartile (Q3) and the first quartile (Q1):\n",
    "\n",
    "\\[\n",
    "\\text{IQR} = Q3 - Q1\n",
    "\\]\n",
    "\n",
    "- **Q1 (First Quartile)**: The value below which 25% of the data falls.\n",
    "- **Q3 (Third Quartile)**: The value below which 75% of the data falls.\n",
    "\n",
    "The IQR helps quantify the spread of the middle half of the data, excluding the extremes.\n",
    "\n",
    "---\n",
    "\n",
    "### **How is IQR Used to Detect Outliers?**\n",
    "\n",
    "Outliers are data points that fall significantly outside the typical range of the dataset. The IQR method identifies outliers as values that are unusually far from the quartiles:\n",
    "\n",
    "1. **Calculate the IQR**:\n",
    "   \\[\n",
    "   \\text{IQR} = Q3 - Q1\n",
    "   \\]\n",
    "\n",
    "2. **Determine the Lower and Upper Boundaries**:\n",
    "   - **Lower Boundary**: \n",
    "     \\[\n",
    "     Q1 - 1.5 \\times \\text{IQR}\n",
    "     \\]\n",
    "   - **Upper Boundary**:\n",
    "     \\[\n",
    "     Q3 + 1.5 \\times \\text{IQR}\n",
    "     \\]\n",
    "\n",
    "3. **Identify Outliers**:\n",
    "   - Any value below the lower boundary or above the upper boundary is considered an outlier.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example**:\n",
    "\n",
    "Consider the dataset: \\( [4, 7, 8, 10, 15, 20, 30] \\)\n",
    "\n",
    "1. **Find Q1 and Q3**:\n",
    "   - Q1 (25th percentile): \\( 7 \\)\n",
    "   - Q3 (75th percentile): \\( 20 \\)\n",
    "\n",
    "2. **Calculate IQR**:\n",
    "   \\[\n",
    "   \\text{IQR} = Q3 - Q1 = 20 - 7 = 13\n",
    "   \\]\n",
    "\n",
    "3. **Determine the Boundaries**:\n",
    "   - Lower Boundary:\n",
    "     \\[\n",
    "     Q1 - 1.5 \\times \\text{IQR} = 7 - 1.5 \\times 13 = -12.5\n",
    "     \\]\n",
    "   - Upper Boundary:\n",
    "     \\[\n",
    "     Q3 + 1.5 \\times \\text{IQR} = 20 + 1.5 \\times 13 = 39.5\n",
    "     \\]\n",
    "\n",
    "4. **Check for Outliers**:\n",
    "   - Any value \\( < -12.5 \\) or \\( > 39.5 \\) is an outlier.\n",
    "   - In this case, there are no outliers since all values fall within the range \\( [-12.5, 39.5] \\).\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Use IQR for Outlier Detection?**\n",
    "\n",
    "1. **Robust to Skewness**: Unlike the mean and standard deviation, the IQR is unaffected by extreme values or skewed distributions, making it a reliable measure for identifying outliers.\n",
    "\n",
    "2. **Focus on Central Data**: The IQR highlights the spread of the middle 50% of the data, ensuring that outliers are judged relative to the dataset's core.\n",
    "\n",
    "---\n",
    "\n",
    "### **Applications of IQR in Outlier Detection**:\n",
    "- **Data Cleaning**: Removing or investigating outliers in datasets.\n",
    "- **Exploratory Data Analysis**: Understanding variability and identifying anomalies.\n",
    "- **Statistical Modeling**: Ensuring that outliers do not unduly influence regression or machine learning models.\n",
    "\n",
    "---\n",
    "\n",
    "### **Limitations**:\n",
    "1. The \\( 1.5 \\times \\text{IQR} \\) rule is somewhat arbitrary and may not apply to all datasets.\n",
    "2. It may misclassify valid extreme values as outliers, especially in distributions with heavy tails.\n",
    "\n",
    "Despite its limitations, the IQR remains a simple and effective tool for detecting outliers and understanding data variability."
   ]
  },
  {
   "cell_type": "raw",
   "id": "89405122-f274-4edf-9aa5-9ef72daa626f",
   "metadata": {},
   "source": [
    "Q8->\n",
    "### **The Binomial Distribution**\n",
    "\n",
    "The **binomial distribution** is a discrete probability distribution that models the number of successes in a fixed number of independent trials of a binary experiment. Each trial results in one of two outcomes: **success** (with probability \\( p \\)) or **failure** (with probability \\( 1-p \\)).\n",
    "\n",
    "---\n",
    "\n",
    "### **Conditions for Using the Binomial Distribution**\n",
    "\n",
    "The binomial distribution applies under the following conditions:\n",
    "\n",
    "1. **Fixed Number of Trials (\\( n \\))**:\n",
    "   - The experiment consists of a predetermined, finite number of trials (\\( n \\)).\n",
    "   - Example: Flipping a coin 10 times.\n",
    "\n",
    "2. **Binary Outcomes (Success/Failure)**:\n",
    "   - Each trial has only two possible outcomes, often labeled as **success** or **failure**.\n",
    "   - Example: Rolling a die and checking if the outcome is a 6 (success) or not (failure).\n",
    "\n",
    "3. **Constant Probability of Success (\\( p \\))**:\n",
    "   - The probability of success (\\( p \\)) remains the same for every trial.\n",
    "   - Example: The probability of rolling a 6 on a fair die is \\( p = \\frac{1}{6} \\) for each roll.\n",
    "\n",
    "4. **Independence of Trials**:\n",
    "   - The outcome of any one trial does not affect the outcomes of other trials.\n",
    "   - Example: Flipping a coin multiple times; each flip is independent of the others.\n",
    "\n",
    "---\n",
    "\n",
    "### **Probability Mass Function (PMF)**\n",
    "\n",
    "The probability of observing exactly \\( k \\) successes in \\( n \\) trials is given by the **binomial probability mass function**:\n",
    "\n",
    "\\[\n",
    "P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( X \\): Random variable representing the number of successes.\n",
    "- \\( \\binom{n}{k} \\): Binomial coefficient, calculated as \\( \\frac{n!}{k!(n-k)!} \\).\n",
    "- \\( p \\): Probability of success in a single trial.\n",
    "- \\( 1-p \\): Probability of failure in a single trial.\n",
    "- \\( n \\): Total number of trials.\n",
    "- \\( k \\): Number of successes.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples of Binomial Experiments**\n",
    "\n",
    "1. **Tossing a Coin**:\n",
    "   - Toss a fair coin 10 times, and count the number of heads (successes).\n",
    "   - \\( n = 10 \\), \\( p = 0.5 \\).\n",
    "\n",
    "2. **Quality Control**:\n",
    "   - Inspect 20 items and record the number of defective items.\n",
    "   - \\( n = 20 \\), \\( p \\) = probability of an item being defective.\n",
    "\n",
    "3. **Medical Trials**:\n",
    "   - Test a new drug on 50 patients and record how many show improvement.\n",
    "   - \\( n = 50 \\), \\( p \\) = probability of improvement.\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use the Binomial Distribution**\n",
    "\n",
    "1. **Yes**:\n",
    "   - Coin tosses, rolling dice, or other binary experiments with constant probabilities.\n",
    "   - Quality control scenarios where items are independently tested.\n",
    "\n",
    "2. **No**:\n",
    "   - If the number of trials is not fixed (use a **Poisson** or **geometric distribution**).\n",
    "   - If trials are not independent (use a different model like the **hypergeometric distribution**).\n",
    "   - If there are more than two outcomes (consider a **multinomial distribution**).\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Applications**\n",
    "\n",
    "- **Elections**: Predicting the number of voters favoring a candidate.\n",
    "- **Insurance**: Estimating the number of policyholders who will file claims.\n",
    "- **Marketing**: Determining the success rate of email campaigns.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "The binomial distribution is an essential tool for modeling binary experiments where the number of trials is fixed, outcomes are independent, and probabilities remain constant. Its simplicity and flexibility make it widely applicable in fields like statistics, business, and science."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6554857d-955e-4f48-939c-c8a9bae6a204",
   "metadata": {},
   "source": [
    "Q9->\n",
    "### **Properties of the Normal Distribution**\n",
    "\n",
    "The **normal distribution**, also called the **Gaussian distribution**, is a continuous probability distribution widely used in statistics due to its natural occurrence in various phenomena (e.g., heights, test scores, measurement errors). Its properties include:\n",
    "\n",
    "1. **Symmetry**:\n",
    "   - The normal distribution is perfectly symmetric about its mean (\\( \\mu \\)).\n",
    "   - The left and right halves are mirror images.\n",
    "\n",
    "2. **Bell-Shaped Curve**:\n",
    "   - The shape of the curve is bell-like, with most of the data clustered around the mean.\n",
    "\n",
    "3. **Mean, Median, and Mode**:\n",
    "   - These three measures of central tendency are equal and located at the center of the distribution.\n",
    "\n",
    "4. **Unimodal**:\n",
    "   - There is only one peak (mode) in the distribution.\n",
    "\n",
    "5. **Asymptotic**:\n",
    "   - The tails of the curve approach, but never touch, the horizontal axis.\n",
    "\n",
    "6. **Defined by Two Parameters**:\n",
    "   - \\( \\mu \\) (mean): Determines the center of the distribution.\n",
    "   - \\( \\sigma \\) (standard deviation): Determines the spread (width) of the curve.\n",
    "\n",
    "7. **Total Area Under the Curve**:\n",
    "   - The total area under the curve is 1, representing the total probability.\n",
    "\n",
    "8. **Probability Density**:\n",
    "   - The probability density function (PDF) for a normal distribution is:\n",
    "     \\[\n",
    "     f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n",
    "     \\]\n",
    "\n",
    "---\n",
    "\n",
    "### **The Empirical Rule (68-95-99.7 Rule)**\n",
    "\n",
    "The **Empirical Rule** describes how data is distributed in a normal distribution:\n",
    "\n",
    "1. **68% of Data**:\n",
    "   - Approximately **68%** of the data lies within **1 standard deviation** (\\( \\mu \\pm \\sigma \\)) of the mean.\n",
    "   - Example: If \\( \\mu = 100 \\) and \\( \\sigma = 10 \\), then 68% of the data lies between 90 and 110.\n",
    "\n",
    "2. **95% of Data**:\n",
    "   - Approximately **95%** of the data lies within **2 standard deviations** (\\( \\mu \\pm 2\\sigma \\)) of the mean.\n",
    "   - Example: If \\( \\mu = 100 \\) and \\( \\sigma = 10 \\), then 95% of the data lies between 80 and 120.\n",
    "\n",
    "3. **99.7% of Data**:\n",
    "   - Approximately **99.7%** of the data lies within **3 standard deviations** (\\( \\mu \\pm 3\\sigma \\)) of the mean.\n",
    "   - Example: If \\( \\mu = 100 \\) and \\( \\sigma = 10 \\), then 99.7% of the data lies between 70 and 130.\n",
    "\n",
    "---\n",
    "\n",
    "### **Visual Representation**\n",
    "\n",
    "The Empirical Rule can be visualized as follows:\n",
    "\n",
    "```\n",
    "                  99.7%\n",
    "      |-----------|-----------|-----------|\n",
    "      -3σ        -2σ         -1σ          μ          +1σ         +2σ         +3σ\n",
    "    (70)        (80)        (90)        (100)      (110)       (120)       (130)\n",
    "```\n",
    "\n",
    "- 68% lies between \\( -1\\sigma \\) and \\( +1\\sigma \\).\n",
    "- 95% lies between \\( -2\\sigma \\) and \\( +2\\sigma \\).\n",
    "- 99.7% lies between \\( -3\\sigma \\) and \\( +3\\sigma \\).\n",
    "\n",
    "---\n",
    "\n",
    "### **Applications of the Normal Distribution and Empirical Rule**\n",
    "\n",
    "1. **Quality Control**:\n",
    "   - In manufacturing, the rule helps identify products within acceptable tolerance levels.\n",
    "\n",
    "2. **Standardized Tests**:\n",
    "   - Scores on SATs or IQ tests typically follow a normal distribution, and the Empirical Rule helps understand score percentiles.\n",
    "\n",
    "3. **Risk Assessment**:\n",
    "   - In finance, stock price changes often assume normality, with standard deviations used to gauge risk.\n",
    "\n",
    "4. **Outlier Detection**:\n",
    "   - Data points beyond \\( \\mu \\pm 3\\sigma \\) are rare and often considered outliers.\n",
    "\n",
    "---\n",
    "\n",
    "### **Limitations**\n",
    "1. **Assumes Normality**:\n",
    "   - The Empirical Rule only applies to normally distributed data. Skewed or bimodal distributions do not follow this rule.\n",
    "\n",
    "2. **Real-World Deviations**:\n",
    "   - Not all datasets perfectly fit a normal distribution (e.g., financial data often exhibit \"fat tails\").\n",
    "\n",
    "Despite its limitations, the normal distribution and Empirical Rule are invaluable tools in statistics for summarizing and analyzing data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "696e074f-707e-4ffc-b642-b36d2c7eb954",
   "metadata": {},
   "source": [
    "Q10->\n",
    "### **Real-Life Example of a Poisson Process**\n",
    "\n",
    "A common example of a **Poisson process** is the number of customers arriving at a bank within an hour. Suppose historical data shows that, on average, **10 customers** arrive at the bank per hour. We can use the **Poisson distribution** to calculate the probability of a specific number of arrivals.\n",
    "\n",
    "---\n",
    "\n",
    "### **Poisson Distribution Formula**\n",
    "\n",
    "The probability of observing \\( k \\) events in a fixed interval is given by:\n",
    "\n",
    "\\[\n",
    "P(X = k) = \\frac{e^{-\\lambda} \\lambda^k}{k!}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( \\lambda \\): Average number of events in the interval (mean).\n",
    "- \\( k \\): Specific number of events.\n",
    "- \\( e \\): Euler's number (\\( \\approx 2.718 \\)).\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Scenario**: What is the probability that exactly 7 customers arrive at the bank in one hour if the average arrival rate is \\( \\lambda = 10 \\) customers per hour?\n",
    "\n",
    "*Solution**:\n",
    "\n",
    "1. Identify parameters:\n",
    "   - \\( \\lambda = 10 \\)\n",
    "   - \\( k = 7 \\)\n",
    "\n",
    "2. Use the formula:\n",
    "\n",
    "\\[\n",
    "P(X = 7) = \\frac{e^{-10} \\cdot 10^7}{7!}\n",
    "\\]\n",
    "\n",
    "3. Calculate step-by-step:\n",
    "   - \\( e^{-10} \\approx 0.000045 \\) (use a calculator or software for precision).\n",
    "   - \\( 10^7 = 10,000,000 \\).\n",
    "   - \\( 7! = 7 \\times 6 \\times 5 \\times 4 \\times 3 \\times 2 \\times 1 = 5040 \\).\n",
    "\n",
    "\\[\n",
    "P(X = 7) = \\frac{0.000045 \\cdot 10,000,000}{5040}\n",
    "\\]\n",
    "\n",
    "4. Simplify:\n",
    "\n",
    "\\[\n",
    "P(X = 7) = \\frac{450}{5040} \\approx 0.0893\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "*Interpretation**\n",
    "\n",
    "The probability that exactly 7 customers arrive at the bank in one hour is approximately **8.93%**.\n",
    "\n",
    "---\n",
    "\n",
    "Applications of the Poisson Process**\n",
    "1. **Customer Arrivals**: At banks, restaurants, or call centers.\n",
    "2. **Traffic Flow**: The number of cars passing through a toll booth in an hour.\n",
    "3. **Defects in Manufacturing**: The number of defects in a batch of items.\n",
    "4. **Natural Phenomena**: Earthquake occurrences in a region over time.\n",
    "\n",
    "The Poisson distribution is ideal for modeling events that occur independently and at a constant average rate over a fixed interval."
   ]
  },
  {
   "cell_type": "raw",
   "id": "87d5e623-130e-4959-9bbf-8f97e7495ce6",
   "metadata": {},
   "source": [
    "Q11->\n",
    "### **What is a Random Variable?**\n",
    "\n",
    "A **random variable** is a numerical outcome of a random process or experiment. It is a variable whose value is determined by the outcome of a random event. Random variables are used to quantify uncertainty in statistical models and are the foundation for probability theory.\n",
    "\n",
    "Random variables are typically denoted by uppercase letters, such as \\( X \\), \\( Y \\), or \\( Z \\).\n",
    "\n",
    "---\n",
    "\n",
    "### **Types of Random Variables**\n",
    "\n",
    "There are two main types of random variables:\n",
    "\n",
    "1. **Discrete Random Variables**:\n",
    "   - A **discrete random variable** can take on only a **finite** or **countable** number of distinct values.\n",
    "   - These values are typically integers or specific, separate values.\n",
    "   - Example: The number of heads in 5 coin tosses, the number of customers arriving at a store in an hour, or the number of goals scored in a soccer match.\n",
    "   \n",
    "   **Characteristics**:\n",
    "   - The set of possible values is countable (e.g., 0, 1, 2, 3, ...).\n",
    "   - The probability distribution of a discrete random variable is given by a **probability mass function (PMF)**, which assigns probabilities to each possible outcome.\n",
    "\n",
    "   **Example**:\n",
    "   - If a die is rolled, the possible outcomes (discrete random variable) are \\( 1, 2, 3, 4, 5, 6 \\).\n",
    "\n",
    "2. **Continuous Random Variables**:\n",
    "   - A **continuous random variable** can take on **any value** within a given range or interval. The set of possible values is **uncountably infinite**.\n",
    "   - These variables typically represent measurements, such as time, distance, height, or temperature.\n",
    "   - Example: The exact height of a person, the amount of rainfall in a year, or the time it takes to complete a task.\n",
    "\n",
    "   **Characteristics**:\n",
    "   - The set of possible values is uncountable, meaning it can take any value within a continuous interval (e.g., any real number between 0 and 10).\n",
    "   - The probability distribution of a continuous random variable is described by a **probability density function (PDF)**. The probability of a specific outcome is zero, but the probability of the variable falling within an interval can be found by integrating the PDF over that interval.\n",
    "\n",
    "   **Example**:\n",
    "   - The time it takes for a car to travel from one city to another is a continuous random variable that could take any value within a certain range (e.g., between 0 and 10 hours).\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Differences Between Discrete and Continuous Random Variables**\n",
    "\n",
    "| **Feature**                    | **Discrete Random Variable**                          | **Continuous Random Variable**                     |\n",
    "|---------------------------------|--------------------------------------------------------|----------------------------------------------------|\n",
    "| **Possible Values**             | Finite or countably infinite values (e.g., 0, 1, 2, 3) | Infinite values within a range (e.g., any real number between 0 and 10) |\n",
    "| **Nature of Outcomes**          | Separate, distinct outcomes                            | Outcomes form a continuous range or interval       |\n",
    "| **Probability Function**        | Probability mass function (PMF)                       | Probability density function (PDF)                 |\n",
    "| **Example**                     | Number of heads in 3 coin flips, number of students in a class | Height of a person, time taken to run a race       |\n",
    "| **Probability of Specific Outcome** | Positive probability for specific outcomes (e.g., \\( P(X = 3) \\)) | Probability of a specific outcome is zero, but probability in an interval is nonzero (e.g., \\( P(3 < X < 5) \\)) |\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "1. **Discrete Random Variable Example**:\n",
    "   - **Scenario**: A box contains 5 red balls and 3 blue balls. If you randomly draw one ball, the number of red balls drawn (denoted as \\( X \\)) is a discrete random variable.\n",
    "   - **Possible outcomes**: \\( X \\) can only be 0 (if a blue ball is drawn) or 1 (if a red ball is drawn).\n",
    "\n",
    "2. **Continuous Random Variable Example**:\n",
    "   - **Scenario**: A car’s speed is measured as it passes a radar gun. The speed (denoted as \\( Y \\)) is a continuous random variable.\n",
    "   - **Possible outcomes**: \\( Y \\) could take any value within a specified range, such as any speed between 0 and 100 km/h.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "- A **discrete random variable** takes on distinct, separate values, often countable.\n",
    "- A **continuous random variable** can take on any value within a given range and is not countable.\n",
    "  \n",
    "Understanding the distinction between these types of random variables is crucial for choosing the correct methods and techniques for probability analysis and statistical modeling."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4574aaa-657e-4521-ade2-56ae7fe83daf",
   "metadata": {},
   "source": [
    "Q12->\n",
    "### **Example Dataset:**\n",
    "\n",
    "Let's say we have a dataset that shows the number of hours studied and the corresponding scores on a test for 5 students:\n",
    "\n",
    "| **Student** | **Hours Studied (X)** | **Test Score (Y)** |\n",
    "|-------------|-----------------------|--------------------|\n",
    "| 1           | 2                     | 50                 |\n",
    "| 2           | 4                     | 60                 |\n",
    "| 3           | 5                     | 70                 |\n",
    "| 4           | 6                     | 80                 |\n",
    "| 5           | 8                     | 90                 |\n",
    "\n",
    "### **Step 1: Calculate Covariance**\n",
    "\n",
    "The **covariance** measures the joint variability of two random variables. It tells us the direction of the linear relationship between the variables. The formula for covariance is:\n",
    "\n",
    "\\[\n",
    "\\text{Cov}(X, Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y})\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( X_i \\) and \\( Y_i \\) are the values of the two variables.\n",
    "- \\( \\bar{X} \\) and \\( \\bar{Y} \\) are the means of the variables \\( X \\) and \\( Y \\).\n",
    "- \\( n \\) is the number of data points (in this case, 5).\n",
    "\n",
    "#### **Step 1.1: Calculate Means**\n",
    "\n",
    "\\[\n",
    "\\bar{X} = \\frac{2 + 4 + 5 + 6 + 8}{5} = 5\n",
    "\\]\n",
    "\\[\n",
    "\\bar{Y} = \\frac{50 + 60 + 70 + 80 + 90}{5} = 70\n",
    "\\]\n",
    "\n",
    "#### **Step 1.2: Calculate the Covariance**\n",
    "\n",
    "Now, we'll calculate the covariance using the formula:\n",
    "\n",
    "\\[\n",
    "\\text{Cov}(X, Y) = \\frac{1}{5-1} \\left[ (2 - 5)(50 - 70) + (4 - 5)(60 - 70) + (5 - 5)(70 - 70) + (6 - 5)(80 - 70) + (8 - 5)(90 - 70) \\right]\n",
    "\\]\n",
    "\n",
    "Breaking it down:\n",
    "\n",
    "\\[\n",
    "\\text{Cov}(X, Y) = \\frac{1}{4} \\left[ (-3)(-20) + (-1)(-10) + (0)(0) + (1)(10) + (3)(20) \\right]\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "\\text{Cov}(X, Y) = \\frac{1}{4} \\left[ 60 + 10 + 0 + 10 + 60 \\right] = \\frac{140}{4} = 35\n",
    "\\]\n",
    "\n",
    "So, the **covariance** is **35**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Calculate Correlation**\n",
    "\n",
    "The **correlation** (specifically the **Pearson correlation coefficient**) standardizes the covariance and measures the strength and direction of the linear relationship between two variables. The formula is:\n",
    "\n",
    "\\[\n",
    "r = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( \\text{Cov}(X, Y) \\) is the covariance.\n",
    "- \\( \\sigma_X \\) and \\( \\sigma_Y \\) are the standard deviations of \\( X \\) and \\( Y \\).\n",
    "\n",
    "#### **Step 2.1: Calculate the Standard Deviations**\n",
    "\n",
    "The standard deviation \\( \\sigma_X \\) is calculated as:\n",
    "\n",
    "\\[\n",
    "\\sigma_X = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})^2}\n",
    "\\]\n",
    "\n",
    "For \\( X \\) (hours studied):\n",
    "\\[\n",
    "\\sigma_X = \\sqrt{\\frac{1}{4} \\left[ (2 - 5)^2 + (4 - 5)^2 + (5 - 5)^2 + (6 - 5)^2 + (8 - 5)^2 \\right]}\n",
    "\\]\n",
    "\\[\n",
    "\\sigma_X = \\sqrt{\\frac{1}{4} \\left[ 9 + 1 + 0 + 1 + 9 \\right]} = \\sqrt{\\frac{20}{4}} = \\sqrt{5} \\approx 2.236\n",
    "\\]\n",
    "\n",
    "For \\( Y \\) (test scores):\n",
    "\\[\n",
    "\\sigma_Y = \\sqrt{\\frac{1}{4} \\left[ (50 - 70)^2 + (60 - 70)^2 + (70 - 70)^2 + (80 - 70)^2 + (90 - 70)^2 \\right]}\n",
    "\\]\n",
    "\\[\n",
    "\\sigma_Y = \\sqrt{\\frac{1}{4} \\left[ 400 + 100 + 0 + 100 + 400 \\right]} = \\sqrt{\\frac{1000}{4}} = \\sqrt{250} \\approx 15.811\n",
    "\\]\n",
    "\n",
    "#### **Step 2.2: Calculate the Correlation**\n",
    "\n",
    "Now, calculate the Pearson correlation coefficient:\n",
    "\n",
    "\\[\n",
    "r = \\frac{35}{2.236 \\times 15.811} \\approx \\frac{35}{35.37} \\approx 0.989\n",
    "\\]\n",
    "\n",
    "So, the **correlation** is approximately **0.989**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation of Results**\n",
    "\n",
    "- **Covariance**: The covariance of 35 indicates that as the number of hours studied increases, the test score tends to increase as well, since the covariance is positive. However, covariance alone does not tell us the strength of the relationship or the scale of the variables, so we need to look at the correlation for that.\n",
    "  \n",
    "- **Correlation**: The correlation of **0.989** indicates a very strong positive linear relationship between the number of hours studied and the test score. This means that the more hours a student studies, the higher their test score is likely to be, and this relationship is nearly perfect.\n",
    "\n",
    "### **Conclusion**\n",
    "- **Covariance** gives us a measure of the direction of the relationship (positive or negative), but **correlation** standardizes that measure to indicate the strength of the relationship between the two variables. In this case, the high correlation suggests that hours studied and test scores are strongly related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65a581-0bec-4a95-8f17-0e051a35ffdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
